{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for coronavirus open citations visualisation\n",
    "\n",
    "This Python notebook contains all the Python code to retrieve all the data used for creating the [Coronavirus Open Citations Dataset](https://opencitations.github.io/coronavirus/). In particular, we used the Crossref API and the unifying REST API for all the OpenCitations Indexes for getting all the information needed for the visualisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "The next code imports all the module needed and set up the basic variables used for retrieving the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from requests.exceptions import Timeout, ConnectionError\n",
    "from json import loads, load, dump\n",
    "from re import sub\n",
    "from os.path import exists\n",
    "from os import makedirs, sep\n",
    "from csv import reader, writer\n",
    "import logging\n",
    "from urllib.parse import quote\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \n",
    "    \"COVID-19 / OpenCitations \"\n",
    "    \"(http://opencitations.net; mailto:contact@opencitations.net)\"\n",
    "}\n",
    "\n",
    "# the base directory where to store the files with the full data\n",
    "data_dir = \"data\"\n",
    "\n",
    "# the CSV document containing the DOIs of the articles relevant for the analysis\n",
    "doi_file = data_dir + sep + \"dois.csv\"\n",
    "\n",
    "# the JSON document containing the citations of the articles relevant for the analysis\n",
    "cit_file = data_dir + sep + \"citations.json\"\n",
    "\n",
    "# the CSV document containing the DOIs of the articles relevant for the analysis that do not have references deposited in Crossref\n",
    "doi_no_ref_file = data_dir + sep + \"dois_no_ref.csv\"\n",
    "\n",
    "# the JSON document containing the metadata of the articles involved in the relevant citations\n",
    "met_file = data_dir + sep + \"metadata.json\"\n",
    "\n",
    "# the CSV document containing the DOIs of the articles for which Crossref does not return any information\n",
    "nod_file = data_dir + sep + \"metadata_not_found.csv\"\n",
    "\n",
    "# the base directory containing all the material for the visualisation\n",
    "vis_dir = \"docs\"\n",
    "\n",
    "# the directory where to store the files with the partial data used in the visualisation\n",
    "vis_data_dir = vis_dir + sep + data_dir\n",
    "\n",
    "# the JSON document containing the citations of the articles relevant for the visualisation\n",
    "vis_cit_file = vis_data_dir + sep + \"citations.json\"\n",
    "\n",
    "# the JSON document containing the metadata of the articles used in the visualisation\n",
    "vis_met_file = vis_data_dir + sep + \"metadata.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to debug the following code snippets, it is possible to set the logger to a debug level (`logging.DEBUG`). If debug messages are not needed, specify the level at `logging.INFO`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the following variable to logging.INFO for removing debug, or logging.DEBUG to add debug messages\n",
    "logging_level = logging.INFO\n",
    "\n",
    "logging.basicConfig(format='%(levelname)s: %(message)s.')\n",
    "log = logging.getLogger()\n",
    "log.setLevel(logging_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "\n",
    "The following code retrieves the list of relevant articles talking about coronaviruses using the Crossref API. It looks for all the articles which contain the word \"coronavirus\", \"covid19\", \"sarscov\", \"ncov2019\", and \"2019ncov\", either in their title or abstract. All these data are stored in the file `doi_file`. If the file already exists on the file system, the process will not run. Thus, to launch again the process, it is needed to remove the file `doi_file` from the file system first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Total DOIs available: 11842.\n"
     ]
    }
   ],
   "source": [
    "crossref_query = \"https://api.crossref.org/works?query.bibliographic=coronavirus+OR+covid19+OR+sarscov+OR+ncov2019+OR+2019ncov&rows=1000&cursor=*\"\n",
    "dois = set()\n",
    "cursors = set()\n",
    "next_cursor = \"*\"\n",
    "\n",
    "if not exists(doi_file):\n",
    "    logging.debug(\"The file with DOIs does not exist: start querying Crossref for retrieving data\")\n",
    "\n",
    "    while next_cursor:\n",
    "        if next_cursor not in cursors:\n",
    "            log.debug(f\"Current cursor for querying Crossref: '{next_cursor}'\")\n",
    "            cursors.add(next_cursor)\n",
    "            crossref_data = get(sub(\"&cursor=.+$\", \"&cursor=\", crossref_query) + quote(next_cursor), \n",
    "                                headers=headers)\n",
    "            if crossref_data.status_code == 200:\n",
    "                crossref_data.encoding = \"utf-8\"\n",
    "                if crossref_json := loads(crossref_data.text).get(\"message\"):\n",
    "                    next_cursor = crossref_json.get(\"next-cursor\")\n",
    "                    for item in crossref_json.get(\"items\"):\n",
    "                        dois.add(item.get(\"DOI\"))\n",
    "                else:\n",
    "                    log.debug(f\"Crossref response does not contain a 'message' \" \n",
    "                              f\"item:\\n{crossref_data.text}\")\n",
    "            else:\n",
    "                log.debug(f\"The request to Crossref end up with a non-OK status code \" \n",
    "                          f\"('{crossref_data.status_code}'): stopping the download\\n\" + crossref_data.text)\n",
    "                next_cursor = None\n",
    "        else:\n",
    "            logging.debug(f\"Current cursor '{next_cursor}' already used: stopping the download\")\n",
    "            next_cursor = None\n",
    "    \n",
    "    if not exists(data_dir):\n",
    "        makedirs(data_dir)\n",
    "    with open(doi_file, \"w\") as f:\n",
    "        csv_writer = writer(f)\n",
    "        for doi in dois:\n",
    "            csv_writer.writerow((doi, ))\n",
    "        \n",
    "else:\n",
    "    log.debug(\"The file with DOIs exist: load information directly from there\")\n",
    "    with open(doi_file) as f:\n",
    "        csv_reader = reader(f)\n",
    "        for doi, in csv_reader:\n",
    "            dois.add(doi)\n",
    "\n",
    "log.info(f\"Total DOIs available: {len(dois)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code retrieves all the citations which involve the DOIs of the articles obtained in the previous step, either as a citing entity or as a cited entity. It uses the unifying REST API for all the OpenCitations Indexes for getting the citation information, thus using all the OpenCitations Indexes currently available, i.e. COCI and CROCI. All the citation data are stored in the file indicated by the variable `cit_file` in a JSON format compatible with the one used by Cytoscape JS - which is the tool used for visualising the data. If the file `cit_file` already exists on the file system, the process will not run. Thus, to launch again the process, it is needed to remove the file `cit_file` from the file system first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Total citations available: 189697. Number of articles with references deposited in Crossref and available in the OpenCitations Indexes: 3348 out of 11842 total articles retrieved in Crossref.\n"
     ]
    }
   ],
   "source": [
    "citations = list()\n",
    "opencitations_query = 'https://opencitations.net/index/api/v1/%s/%s?json=array(\"; \",citing).array(\"; \",cited).dict(\" => \",citing,source,doi).dict(\" => \",cited,source,doi)'\n",
    "cit_id = 0    \n",
    "\n",
    "def extract_citations(res, cit_id):\n",
    "    result = list()\n",
    "    res.encoding = \"utf-8\"\n",
    "    for citation in loads(res.text):\n",
    "        cit_id += 1\n",
    "        citation_item = {\n",
    "            \"id\": str(cit_id), \n",
    "            \"source\": citation[\"citing\"][0][\"doi\"], \n",
    "            \"target\": citation[\"cited\"][0][\"doi\"]\n",
    "        }\n",
    "\n",
    "        result.append(citation_item)\n",
    "    \n",
    "    return result, cit_id\n",
    "        \n",
    "if not exists(cit_file):\n",
    "    log.debug(\"The file with citations does not exist: start querying OpenCitations \"\n",
    "                  \"for retrieving citation data\")\n",
    "    for doi in dois:\n",
    "        logging.debug(f\"Process DOI '{doi}'\")\n",
    "        reference_data = get(opencitations_query % (\"references\", doi), headers=headers)\n",
    "        if reference_data.status_code == 200:\n",
    "            all_citations, cit_id = extract_citations(reference_data, cit_id)\n",
    "            for citation in all_citations:\n",
    "                if citation not in citations:\n",
    "                    citations.append(citation)\n",
    "        else:\n",
    "            log.warning(f\"Status code '{reference_data.status_code}' when requesting references for \"\n",
    "                            \"DOI '{doi}'\")\n",
    "        citation_data = get(opencitations_query % (\"citations\", doi), headers=headers)\n",
    "        if citation_data.status_code == 200:\n",
    "            all_citations, cit_id = extract_citations(citation_data, cit_id)\n",
    "            for citation in all_citations:\n",
    "                if citation not in citations:\n",
    "                    citations.append(citation)\n",
    "        else:\n",
    "            log.warning(f\"Status code '{citation_data.status_code}' when requesting citations for \"\n",
    "                            \"DOI '{doi}'\")\n",
    "    \n",
    "    with open(cit_file, \"w\") as f:\n",
    "        dump(citations, f, ensure_ascii=False, indent=0)\n",
    "    \n",
    "else:\n",
    "    log.debug(\"The file with citations exist: load information directly from there.\")\n",
    "    with open(cit_file) as f:\n",
    "        citations.extend(load(f))\n",
    "\n",
    "citing_dois = set()\n",
    "for citation in citations:\n",
    "    citing_dois.add(citation[\"source\"])\n",
    "        \n",
    "articles_with_references = set()\n",
    "articles_without_references = set()\n",
    "for doi in dois:\n",
    "    if doi in citing_dois:\n",
    "        articles_with_references.add(doi)\n",
    "    else:\n",
    "        articles_without_references.add(doi)\n",
    "\n",
    "if not exists(doi_no_ref_file):\n",
    "    with open(doi_no_ref_file, \"w\") as f:\n",
    "        csv_writer = writer(f)\n",
    "        for doi in articles_without_references:\n",
    "            csv_writer.writerow((doi, ))\n",
    "        \n",
    "log.info(f\"Total citations available: {len(citations)}. Number of articles with references \"\n",
    "         f\"deposited in Crossref and available in the OpenCitations Indexes: \"\n",
    "         f\"{len(articles_with_references)} out of {len(dois)} total articles retrieved in Crossref\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the following code uses the Crossref API again to identify all the basic metadata (i.e. authors, year of publication, title, publication venue, and DOI) of the articles involved in all the citations retrieved in the previous step. Only the metadata of the articles for which Crossref has metadata are stored in the file `met_file`. If the file already exists on the file system, the process will not run. Thus, to launch again the process, it is needed to remove the file `met_file` from the file system first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: The total number of articles involved in the citations retrieved are 49719. The total number of articles with available metadata is 49719, and there are 0 articles with no metadata found.\n"
     ]
    }
   ],
   "source": [
    "crossref_query = \"https://api.crossref.org/works/\"\n",
    "\n",
    "def normalise(o):\n",
    "    if o is None:\n",
    "        s = \"\"\n",
    "    else:\n",
    "        s = str(o)\n",
    "    return sub(\"\\s+\", \" \", s).strip()\n",
    "\n",
    "def create_title_from_list(title_list):\n",
    "    cur_title = \"\"\n",
    "\n",
    "    for title in title_list:\n",
    "        strip_title = title.strip()\n",
    "        if strip_title != \"\":\n",
    "            if cur_title == \"\":\n",
    "                cur_title = strip_title\n",
    "            else:\n",
    "                cur_title += \" - \" + strip_title\n",
    "\n",
    "    return normalise(cur_title.title())\n",
    "\n",
    "def get_basic_metadata(body):\n",
    "    authors = []\n",
    "    for author in body.get(\"author\", []):\n",
    "        authors.append(normalise(author.get(\"family\", \"\").title()))\n",
    "\n",
    "    year = \"\"\n",
    "    if \"issued\" in body and \"date-parts\" in body[\"issued\"] and len(body[\"issued\"][\"date-parts\"]) and \\\n",
    "            len(body[\"issued\"][\"date-parts\"][0]):\n",
    "        year = normalise(body[\"issued\"][\"date-parts\"][0][0])\n",
    "\n",
    "    title = \"\"\n",
    "    if \"title\" in body:\n",
    "        title = create_title_from_list(body.get(\"title\", []))\n",
    "\n",
    "    source_title = \"\"\n",
    "    if \"container-title\" in body:\n",
    "        source_title = create_title_from_list(body.get(\"container-title\", []))\n",
    "\n",
    "    return \", \".join(authors), year, title, source_title\n",
    "\n",
    "dois_in_citations = set()\n",
    "for citation in citations:\n",
    "    dois_in_citations.add(citation[\"source\"])\n",
    "    dois_in_citations.add(citation[\"target\"])\n",
    "\n",
    "existing_doi = set()\n",
    "metadata = []\n",
    "if exists(met_file):\n",
    "    with open(met_file) as f:\n",
    "        for article in load(f):\n",
    "            existing_doi.add(article[\"id\"])\n",
    "            metadata.append(article)\n",
    "\n",
    "if exists(nod_file):\n",
    "    with open(nod_file) as f:\n",
    "        csv_reader = reader(f)\n",
    "        for doi, in csv_reader:\n",
    "            existing_doi.add(doi)\n",
    "\n",
    "dois_not_found = []\n",
    "for doi in dois_in_citations.difference(existing_doi):\n",
    "    log.debug(f\"Requesting Crossref metadata for DOI '{doi}'\")\n",
    "    try:\n",
    "        article = get(crossref_query + doi, headers=headers, timeout=30)\n",
    "        if article.status_code == 200:\n",
    "            article.encoding = \"utf-8\"\n",
    "            if article_json := loads(article.text).get(\"message\"):\n",
    "                author, year, title, source_title = get_basic_metadata(article_json)\n",
    "                metadata.append({\n",
    "                    \"id\": doi,\n",
    "                    \"author\": author,\n",
    "                    \"year\": year,\n",
    "                    \"title\": title,\n",
    "                    \"source_title\": source_title\n",
    "                })\n",
    "            else:\n",
    "                log.warning(f\"No article metadata in Crossref for DOI '{doi}'\")\n",
    "                dois_not_found.append(doi)\n",
    "        else:\n",
    "            dois_not_found.append(doi)\n",
    "            log.warning(f\"Status code '{article.status_code}' when requesting Crossref metadata \"\n",
    "                        f\"for DOI '{doi}'\")\n",
    "    except Timeout:\n",
    "        dois_not_found.append(doi)\n",
    "        log.warning(f\"Timeout when querying Crossref for DOI '{doi}'\")\n",
    "    except ConnectionError:\n",
    "        dois_not_found.append(doi)\n",
    "        log.warning(f\"Connection issues when querying Crossref for DOI '{doi}'\")\n",
    "\n",
    "with open(met_file, \"w\") as f:\n",
    "    dump(metadata, f, ensure_ascii=False, indent=0)\n",
    "        \n",
    "if dois_not_found:\n",
    "    with open(nod_file, \"w\") as f:\n",
    "        csv_writer = writer(f)\n",
    "        for doi in dois_not_found:\n",
    "            csv_writer.writerow((doi, ))\n",
    "\n",
    "log.info(f\"The total number of articles involved in the citations retrieved \"\n",
    "         f\"are {len(metadata) + len(dois_not_found)}. \"\n",
    "         f\"The total number of articles with available metadata is {len(metadata)}, \"\n",
    "         f\"and there are {len(dois_not_found)} articles with no metadata found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the DOIs of the articles for which Crossref does not provide any metadata are stored in the file `nod_file`. In this case, the metadata for that articles must be completed by hand, and then added to the file `met_file`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for the visualisation\n",
    "\n",
    "For visualisation purposes, we selected only a partial subset of the citations and the articles retrived in the previous steps. In particular, we considered only: \n",
    "\n",
    "1. the citations having both the DOIs of the citing entity and the cited entity included in the file `doi_file`;\n",
    "2. the articles that received, overall, at least ten citations per year since their publication date.\n",
    "\n",
    "The following code stores the citations and the metadata of the articles used in the visualisation in the files `vis_cit_file` and `vis_met_file` respectively. If the files already exist on the file system, the process will not run. Thus, to launch again the process, it is needed to remove the files `vis_cit_file` and `vis_met_file` from the file system first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Number of citations (902) and articles (109) selected for visualization purposes.\n"
     ]
    }
   ],
   "source": [
    "min_num_cits_per_year = 20\n",
    "\n",
    "# Consider only the citations from and to articles of the selected dataset\n",
    "filtered_citations = []\n",
    "number_of_citations = {}\n",
    "for citation in citations:\n",
    "    if citation[\"target\"] in dois:\n",
    "        filtered_citations.append(citation)\n",
    "        number_of_citations[citation[\"target\"]] = number_of_citations.get(citation[\"target\"], 0) + 1\n",
    "\n",
    "# Publication years of the articles\n",
    "pub_year = {}\n",
    "for article in metadata:\n",
    "    pub_year[article[\"id\"]] = int(article[\"year\"]) if article[\"year\"] else 0\n",
    "\n",
    "current_year = 2020\n",
    "only_highly_cited = []\n",
    "dois_in_selected_citations = set()\n",
    "for citation in filtered_citations:\n",
    "    if citation[\"source\"] in dois and citation[\"target\"] in dois and \\\n",
    "       number_of_citations.get(citation[\"source\"], 0) >= ((current_year - pub_year[citation[\"source\"]] + 1) * min_num_cits_per_year) and \\\n",
    "       number_of_citations.get(citation[\"target\"], 0) >= ((current_year - pub_year[citation[\"target\"]] + 1) * min_num_cits_per_year):\n",
    "        dois_in_selected_citations.add(citation[\"source\"])\n",
    "        dois_in_selected_citations.add(citation[\"target\"])\n",
    "        only_highly_cited.append(citation)\n",
    "\n",
    "log.info(f\"Number of citations ({len(only_highly_cited)}) and articles \"\n",
    "         f\"({len(dois_in_selected_citations)}) selected for visualization purposes\")\n",
    "\n",
    "if not exists(vis_data_dir):\n",
    "    makedirs(vis_data_dir)\n",
    "\n",
    "if not exists(vis_cit_file):\n",
    "    with open(vis_cit_file, \"w\") as f:\n",
    "        dump(only_highly_cited, f, ensure_ascii=False, indent=0)\n",
    "\n",
    "if not exists(vis_met_file):\n",
    "    partial_metadata = []\n",
    "    with open(met_file) as f:\n",
    "        for article in load(f):\n",
    "            if article[\"id\"] in dois_in_selected_citations:\n",
    "                article[\"count\"] = number_of_citations.get(article[\"id\"], 0)\n",
    "                partial_metadata.append(article)\n",
    "\n",
    "    with open(vis_met_file, \"w\") as f:\n",
    "        dump(partial_metadata, f, ensure_ascii=False, indent=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License\n",
    "\n",
    "### Code\n",
    "\n",
    "Copyright 2020, Silvio Peroni (essepuntato@gmail.com)\n",
    "\n",
    "Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n",
    "\n",
    "### Notebook text\n",
    "Copyright 2020, Silvio Peroni (essepuntato@gmail.com)\n",
    "\n",
    "Attribution 4.0 International (CC BY 4.0) https://creativecommons.org/licenses/by/4.0/legalcode\n",
    "\n",
    "You are free to:\n",
    "\n",
    "* Share — copy and redistribute the material in any medium or format.\n",
    "* Adapt — remix, transform, and build upon the material for any purpose, even commercially.\n",
    "\n",
    "Under the following terms:\n",
    "\n",
    "* Attribution — You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\n",
    "* No additional restrictions — You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.\n",
    "\n",
    "This license is acceptable for Free Cultural Works. The licensor cannot revoke these freedoms as long as you follow the license terms.\n",
    "\n",
    "Notices:\n",
    "\n",
    "* You do not have to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation.\n",
    "* No warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
